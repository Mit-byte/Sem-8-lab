{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a1e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5abf778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"News_dataset.pickle\", 'rb') as data:\n",
    "    df = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e6ef94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name                                            Content  Category  \\\n",
       "0   001.txt  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...  business   \n",
       "1   002.txt  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...  business   \n",
       "2   003.txt  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...  business   \n",
       "3   004.txt  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...  business   \n",
       "4   005.txt  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...  business   \n",
       "\n",
       "  Complete_Filename  id  News_length  \n",
       "0  001.txt-business   1         2569  \n",
       "1  002.txt-business   1         2257  \n",
       "2  003.txt-business   1         1557  \n",
       "3  004.txt-business   1         2421  \n",
       "4  005.txt-business   1         1575  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c1020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c839e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase\n",
    "df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()        \n",
    "\n",
    "# remove punctuations\n",
    "punctuation_signs = list(\"?:!.,;\")                                  \n",
    "df['Content_Parsed_3'] = df['Content_Parsed_2']\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')\n",
    "\n",
    "\n",
    "df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47af3938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan narrowly escapes recession japan economy teetered on the brink of a technical recession in the three months to september figures show revised figures indicated growth of just 01% - and a similar-sized contraction in the previous quarter on an annual basis the data suggests annual growth of just 02% suggesting a much more hesitant recovery than had previously been thought a common technical definition of a recession is two successive quarters of negative growth the government was keen to play down the worrying implications of the data i maintain the view that japan economy remains in a minor adjustment phase in an upward climb and we will monitor developments carefully said economy minister heizo takenaka but in the face of the strengthening yen making exports less competitive and indications of weakening economic conditions ahead observers were less sanguine it painting a picture of a recovery much patchier than previously thought said paul sheard economist at lehman brothers in tokyo improvements in the job market apparently have yet to feed through to domestic demand with private consumption up just 02% in the third quarter'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[5]['Content_Parsed_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c1b012",
   "metadata": {},
   "source": [
    "# WordNet Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d62f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Mitesh Manoj\n",
      "[nltk_data]     Adake\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Mitesh Manoj\n",
      "[nltk_data]     Adake\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Mitesh Manoj\n",
      "[nltk_data]     Adake\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9919f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dc4eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c73440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    # tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    # tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            # if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            # else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "103d445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    lemmatized_text = lemmatize_sentence(df.loc[row]['Content_Parsed_4'])\n",
    "    lemmatized_text_list.append(lemmatized_text)\n",
    "\n",
    "df['Content_Parsed_5'] = lemmatized_text_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bade0417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan narrowly escape recession japan economy teeter on the brink of a technical recession in the three month to september figure show revised figure indicate growth of just 01 % - and a similar-sized contraction in the previous quarter on an annual basis the data suggest annual growth of just 02 % suggest a much more hesitant recovery than have previously be think a common technical definition of a recession be two successive quarter of negative growth the government be keen to play down the worrying implication of the data i maintain the view that japan economy remain in a minor adjustment phase in an upward climb and we will monitor development carefully say economy minister heizo takenaka but in the face of the strengthen yen make export less competitive and indication of weaken economic condition ahead observer be less sanguine it paint a picture of a recovery much patchy than previously think say paul sheard economist at lehman brother in tokyo improvement in the job market apparently have yet to fee through to domestic demand with private consumption up just 02 % in the third quarter'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[5]['Content_Parsed_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b76974",
   "metadata": {},
   "source": [
    "# Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cb68323",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "471d4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
    "\n",
    "for stop_word in stop_words:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86300926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan narrowly escape recession japan economy teeter   brink   technical recession   three month  september figure show revised figure indicate growth   01 % -   similar-sized contraction   previous quarter   annual basis  data suggest annual growth   02 % suggest  much  hesitant recovery   previously  think  common technical definition   recession  two successive quarter  negative growth  government  keen  play   worrying implication   data  maintain  view  japan economy remain   minor adjustment phase   upward climb    monitor development carefully say economy minister heizo takenaka    face   strengthen yen make export less competitive  indication  weaken economic condition ahead observer  less sanguine  paint  picture   recovery much patchy  previously think say paul sheard economist  lehman brother  tokyo improvement   job market apparently  yet  fee   domestic demand  private consumption   02 %   third quarter'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "884d54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the old content_parsed columns\n",
    "\n",
    "list_columns = [\"File_Name\", \"Category\", \"Complete_Filename\", \"Content\", \"Content_Parsed_6\"]\n",
    "df = df[list_columns]\n",
    "\n",
    "df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6876d122",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cd98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_codes = {\n",
    "    'business': 0,\n",
    "    'entertainment': 1,\n",
    "    'politics': 2,\n",
    "    'sport': 3,\n",
    "    'tech': 4\n",
    "}\n",
    "\n",
    "# Category mapping\n",
    "df['Category_Code'] = df['Category']\n",
    "df = df.replace({'Category_Code':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4575af64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Parsed</th>\n",
       "      <th>Category_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>dollar gain  greenspan speech  dollar  hit  hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>yukos unit buyer face loan claim  owner  embat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>high fuel price hit ba profit british airway  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>pernod takeover talk lift domecq share  uk dri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name  Category Complete_Filename  \\\n",
       "0   001.txt  business  001.txt-business   \n",
       "1   002.txt  business  002.txt-business   \n",
       "2   003.txt  business  003.txt-business   \n",
       "3   004.txt  business  004.txt-business   \n",
       "4   005.txt  business  005.txt-business   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...   \n",
       "1  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...   \n",
       "2  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...   \n",
       "3  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...   \n",
       "4  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...   \n",
       "\n",
       "                                      Content_Parsed  Category_Code  \n",
       "0  ad sale boost time warner profit quarterly pro...              0  \n",
       "1  dollar gain  greenspan speech  dollar  hit  hi...              0  \n",
       "2  yukos unit buyer face loan claim  owner  embat...              0  \n",
       "3  high fuel price hit ba profit british airway  ...              0  \n",
       "4  pernod takeover talk lift domecq share  uk dri...              0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbedc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_vectorized = tfidf.fit_transform(df['Content_Parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06bff199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>00051</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>003</th>\n",
       "      <th>004secs</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>0100</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooropa</th>\n",
       "      <th>zornotza</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zubair</th>\n",
       "      <th>zuluaga</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zutons</th>\n",
       "      <th>zvonareva</th>\n",
       "      <th>zvyagintsev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25446 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  0001  00051  001  002  003  004secs  007   01  0100  ...  zoom  \\\n",
       "0  0.0   0.0    0.0  0.0  0.0  0.0      0.0  0.0  0.0   0.0  ...   0.0   \n",
       "1  0.0   0.0    0.0  0.0  0.0  0.0      0.0  0.0  0.0   0.0  ...   0.0   \n",
       "2  0.0   0.0    0.0  0.0  0.0  0.0      0.0  0.0  0.0   0.0  ...   0.0   \n",
       "3  0.0   0.0    0.0  0.0  0.0  0.0      0.0  0.0  0.0   0.0  ...   0.0   \n",
       "4  0.0   0.0    0.0  0.0  0.0  0.0      0.0  0.0  0.0   0.0  ...   0.0   \n",
       "\n",
       "   zooropa  zornotza  zorro  zubair  zuluaga  zurich  zutons  zvonareva  \\\n",
       "0      0.0       0.0    0.0     0.0      0.0     0.0     0.0        0.0   \n",
       "1      0.0       0.0    0.0     0.0      0.0     0.0     0.0        0.0   \n",
       "2      0.0       0.0    0.0     0.0      0.0     0.0     0.0        0.0   \n",
       "3      0.0       0.0    0.0     0.0      0.0     0.0     0.0        0.0   \n",
       "4      0.0       0.0    0.0     0.0      0.0     0.0     0.0        0.0   \n",
       "\n",
       "   zvyagintsev  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "\n",
       "[5 rows x 25446 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf_vectorized = pd.DataFrame(tfidf_vectorized.toarray(), columns=tfidf.get_feature_names())\n",
    "df_tfidf_vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f805002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07049552217154262,\n",
       " 0.07049552217154262,\n",
       " 0.06243614727234318,\n",
       " 0.03269809289193229,\n",
       " 0.051657226357623265,\n",
       " 0.026365272052807164,\n",
       " 0.07677120150944808,\n",
       " 0.07049552217154262,\n",
       " 0.052773135309825754,\n",
       " 0.07049552217154262,\n",
       " 0.07049552217154262,\n",
       " 0.07049552217154262,\n",
       " 0.05167224379413272,\n",
       " 0.05947665439113074,\n",
       " 0.07049552217154262,\n",
       " 0.04940446853513591,\n",
       " 0.055501150291405066,\n",
       " 0.06469243973819575,\n",
       " 0.046108795146465965,\n",
       " 0.04940446853513591,\n",
       " 0.04697463982251519,\n",
       " 0.09335290710711319,\n",
       " 0.04863914669648686,\n",
       " 0.02446102199888857,\n",
       " 0.027518851293778932,\n",
       " 0.03312723422312383,\n",
       " 0.02754809306008016,\n",
       " 0.3654383383191459,\n",
       " 0.02599457381062731,\n",
       " 0.045320597735662146,\n",
       " 0.019435572062414957,\n",
       " 0.03331776122221313,\n",
       " 0.07049552217154262,\n",
       " 0.021237474689931368,\n",
       " 0.032818583167046604,\n",
       " 0.06242989220745722,\n",
       " 0.03448309004101827,\n",
       " 0.03885481346518116,\n",
       " 0.05726618000277693,\n",
       " 0.05633946551607402,\n",
       " 0.026106979845709588,\n",
       " 0.07049552217154262,\n",
       " 0.030212731990061165,\n",
       " 0.02903259982548572,\n",
       " 0.024747084692480933,\n",
       " 0.02775030087434655,\n",
       " 0.033644774816349324,\n",
       " 0.042638286719277635,\n",
       " 0.04350999459313314,\n",
       " 0.03850057824210812,\n",
       " 0.042361104854449716,\n",
       " 0.06926183922770936,\n",
       " 0.052788890112904205,\n",
       " 0.029191801502663737,\n",
       " 0.045320597735662146,\n",
       " 0.04029136390903096,\n",
       " 0.05775245710157849,\n",
       " 0.04057977179728743,\n",
       " 0.03178934705812961,\n",
       " 0.043716960672344166,\n",
       " 0.049013486276965744,\n",
       " 0.03485742962149715,\n",
       " 0.0557063503522934,\n",
       " 0.046388045665300116,\n",
       " 0.055501150291405066,\n",
       " 0.03549162514132905,\n",
       " 0.02754809306008016,\n",
       " 0.03524841187966731,\n",
       " 0.022253154115972604,\n",
       " 0.03885481346518116,\n",
       " 0.05356554244286224,\n",
       " 0.028027352205136833,\n",
       " 0.03077137383815036,\n",
       " 0.02253122740767047,\n",
       " 0.04940446853513591,\n",
       " 0.05947665439113074,\n",
       " 0.0234642222606064,\n",
       " 0.045320597735662146,\n",
       " 0.10133718658892826,\n",
       " 0.03016774134191139,\n",
       " 0.03184347432147292,\n",
       " 0.05920577623647946,\n",
       " 0.03426590240047601,\n",
       " 0.03653788509917784,\n",
       " 0.0317355508504551,\n",
       " 0.020400637601983088,\n",
       " 0.08919451999675457,\n",
       " 0.05633946551607402,\n",
       " 0.02834983587224177,\n",
       " 0.028722588792206617,\n",
       " 0.022644965878791442,\n",
       " 0.08765238684672598,\n",
       " 0.028423133400882972,\n",
       " 0.023506206361970573,\n",
       " 0.02633619548901964,\n",
       " 0.04200923183161529,\n",
       " 0.03783223260672426,\n",
       " 0.12651574229981313,\n",
       " 0.03591255007534613,\n",
       " 0.04557556203786355,\n",
       " 0.03897613473396945,\n",
       " 0.0317355508504551,\n",
       " 0.028423133400882972,\n",
       " 0.03516881267092935,\n",
       " 0.02511826434745945,\n",
       " 0.03501174327316436,\n",
       " 0.026905789346120423,\n",
       " 0.04557556203786355,\n",
       " 0.023422437609406887,\n",
       " 0.029477532278577027,\n",
       " 0.031523597159805836,\n",
       " 0.04728329087859242,\n",
       " 0.02032703338554968,\n",
       " 0.02849704688236224,\n",
       " 0.021385028705427085,\n",
       " 0.05069394175464644,\n",
       " 0.05008552944098982,\n",
       " 0.028277144115224667,\n",
       " 0.04863914669648686,\n",
       " 0.03020048242688452,\n",
       " 0.03168208167341905,\n",
       " 0.035328738031877374,\n",
       " 0.06692919196529436,\n",
       " 0.02245621072662428,\n",
       " 0.026661449952642833,\n",
       " 0.0594601127883611,\n",
       " 0.03391543163392764,\n",
       " 0.07049552217154262,\n",
       " 0.03557421403484619,\n",
       " 0.047935118851778015,\n",
       " 0.3398441749765025,\n",
       " 0.03294074697164047,\n",
       " 0.04760316804025951,\n",
       " 0.04072760137012384,\n",
       " 0.12251340778605413,\n",
       " 0.04940446853513591,\n",
       " 0.04350999459313314,\n",
       " 0.023236824923577495,\n",
       " 0.042361104854449716,\n",
       " 0.044597259998377284,\n",
       " 0.11895330878226149,\n",
       " 0.05290616591440228,\n",
       " 0.1426303430925789,\n",
       " 0.03574175533923969,\n",
       " 0.03783223260672426,\n",
       " 0.04200923183161529,\n",
       " 0.05033791978293211,\n",
       " 0.1281943454709297,\n",
       " 0.03223198900983152,\n",
       " 0.04948535455319025,\n",
       " 0.03885481346518116,\n",
       " 0.10334448758826544,\n",
       " 0.030395031832498205,\n",
       " 0.024579086221709016,\n",
       " 0.04199384450648965,\n",
       " 0.04029136390903096,\n",
       " 0.04330778677886674,\n",
       " 0.02911184047436812,\n",
       " 0.04072760137012384,\n",
       " 0.04760316804025951,\n",
       " 0.07148351067847938,\n",
       " 0.12045189139828769,\n",
       " 0.05387362921538277,\n",
       " 0.09277609133060023,\n",
       " 0.025271236073342432,\n",
       " 0.040566329406822914,\n",
       " 0.0486066350565963,\n",
       " 0.4934686552007983,\n",
       " 0.05473582845275603,\n",
       " 0.024390936747309317,\n",
       " 0.04350999459313314,\n",
       " 0.053379972634861585,\n",
       " 0.05179034618077909,\n",
       " 0.030212731990061165,\n",
       " 0.0321192226891417,\n",
       " 0.21351989053944634,\n",
       " 0.02041543264758364,\n",
       " 0.04557556203786355,\n",
       " 0.05011809618515799]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-zero elements of vector\n",
    "[i for i in list(df_tfidf_vectorized.loc[0]) if i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105be80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
